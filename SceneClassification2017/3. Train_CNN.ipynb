{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train_CNN\n",
    "\n",
    "**Tensorboard**\n",
    "- Input at command: tensorboard --logdir=./log\n",
    "- Input at browser: http://127.0.0.1:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: SceneClassification_Train_CNN_20171028_150251\n",
      "model_path: E:\\SceneClassification\\model\n",
      "model_path: E:\\SceneClassification\\log\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "project_name = 'SceneClassification'\n",
    "step_name = 'Train_CNN'\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "run_name = project_name + '_' + step_name + '_' + time_str\n",
    "print('run_name: ' + run_name)\n",
    "\n",
    "cwd = os.getcwd()\n",
    "model_path = os.path.join(cwd, 'model')\n",
    "log_path = os.path.join(cwd, 'log')\n",
    "print('model_path: ' + model_path)\n",
    "print('model_path: ' + log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00002ff812f48a3df27c321d517a6300ed8da0c3.jpg', '00049a860dca2af378faeb0ee6f435c6063818ef.jpg', '0011a9c9216c3763ffc33641a8ffc975127dc404.jpg', '0045a44cacc7bc9826db9b54d2dcd70b810250f9.jpg', '004b6823145471c6a4ce292e864909fde2d04969.jpg', '0056e4d54eee781117c9d407d03ebf7192126b1f.jpg', '005763f88b25b18ae524b25afcce960403665383.jpg', '005b5444df96e3a155f2a73a8dccc0267e118413.jpg', '005c6ba205a246d0d3c8f73adfd4398b8e483962.jpg', '005de85662d754f98a1476a37b189902800ace91.jpg']\n"
     ]
    }
   ],
   "source": [
    "test_images = os.listdir(os.path.join(cwd, 'input', 'data_test_a', 'test'))\n",
    "print(test_images[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53879, 8192)\n",
      "(8192,)\n",
      "53879\n",
      "(7120, 8192)\n",
      "7120\n",
      "(7040, 8192)\n",
      "Wall time: 6.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(2017)\n",
    "\n",
    "x_train = []\n",
    "y_train = {}\n",
    "x_val = []\n",
    "y_val = {}\n",
    "x_test = []\n",
    "\n",
    "cwd = os.getcwd()\n",
    "feature_cgg16 = os.path.join(cwd, 'model', 'feature_VGG16_{}.h5'.format(171023))\n",
    "feature_cgg19 = os.path.join(cwd, 'model', 'feature_VGG19_{}.h5'.format(171023))\n",
    "feature_resnet50 = os.path.join(cwd, 'model', 'feature_ResNet50_{}.h5'.format(171023))\n",
    "feature_mobilenet = os.path.join(cwd, 'model', 'feature_MobileNet_{}.h5'.format(171023))\n",
    "feature_xception = os.path.join(cwd, 'model', 'feature_Xception_{}.h5'.format(171023))\n",
    "feature_inception = os.path.join(cwd, 'model', 'feature_InceptionV3_{}.h5'.format(171023))\n",
    "for filename in [feature_cgg16, feature_cgg19, feature_resnet50, feature_mobilenet, feature_xception, feature_inception]:\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        x_train.append(np.array(h['train']))\n",
    "        y_train = np.array(h['train_label'])\n",
    "        x_val.append(np.array(h['val']))\n",
    "        y_val = np.array(h['val_label'])\n",
    "        x_test.append(np.array(h['test']))\n",
    "\n",
    "# print(x_train[0].shape)\n",
    "x_train = np.concatenate(x_train, axis=-1)\n",
    "# y_train = np.concatenate(y_train, axis=0)\n",
    "x_val = np.concatenate(x_val, axis=-1)\n",
    "# y_val = np.concatenate(y_val, axis=0)\n",
    "x_test = np.concatenate(x_test, axis=-1)\n",
    "print(x_train.shape)\n",
    "print(x_train.shape[1:])\n",
    "\n",
    "print(len(y_train))\n",
    "print(x_val.shape)\n",
    "print(len(y_val))\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53879, 8192)\n",
      "(53879,)\n"
     ]
    }
   ],
   "source": [
    "# x_train, y_train = shuffle(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53879, 80)\n",
      "(7120, 80)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape array to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target shape:  (91, 91)\n",
      "Extend_widgth:  89\n",
      "Before extend:\n",
      "(53879, 8192)\n",
      "(7120, 8192)\n",
      "(7040, 8192)\n",
      "After extend:\n",
      "(53879, 8281)\n",
      "(7120, 8281)\n",
      "(7040, 8281)\n",
      "After reshape:\n",
      "(53879, 91, 91, 1)\n",
      "(7120, 91, 91, 1)\n",
      "(7040, 91, 91, 1)\n"
     ]
    }
   ],
   "source": [
    "target_shape = (91, 91)\n",
    "\n",
    "extend_widgth = target_shape[0]*target_shape[1] - x_train.shape[1]\n",
    "print('Target shape: ', target_shape)\n",
    "print('Extend_widgth: ', extend_widgth)\n",
    "print('Before extend:')\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "x_train_ext = np.zeros((x_train.shape[0], extend_widgth))\n",
    "x_val_ext = np.zeros((x_val.shape[0], extend_widgth))\n",
    "x_test_ext = np.zeros((x_test.shape[0], extend_widgth))\n",
    "\n",
    "x_train0 = np.column_stack((x_train, x_train_ext))\n",
    "x_val0 = np.column_stack((x_val, x_val_ext))\n",
    "x_test0 = np.column_stack((x_test, x_test_ext))\n",
    "\n",
    "print('After extend:')\n",
    "print(x_train0.shape)\n",
    "print(x_val0.shape)\n",
    "print(x_test0.shape)\n",
    "\n",
    "x_train0 = x_train0.reshape(-1, target_shape[0], target_shape[1], 1)\n",
    "x_val0 = x_val0.reshape(-1, target_shape[0], target_shape[1], 1)\n",
    "x_test0 = x_test0.reshape(-1, target_shape[0], target_shape[1], 1)\n",
    "\n",
    "print('After reshape:')\n",
    "print(x_train0.shape)\n",
    "print(x_val0.shape)\n",
    "print(x_test0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_dir:E:\\SceneClassification\\log\\SceneClassification_Train_CNN_20171028_150251\n"
     ]
    }
   ],
   "source": [
    "def ge_lr(x):\n",
    "    lr = 1.5e-3 * 0.9 ** x\n",
    "    if lr < 1e-4:\n",
    "        lr = 1e-4\n",
    "    print(lr, end=' ')\n",
    "    return lr\n",
    "        \n",
    "# annealer = LearningRateScheduler(lambda x: 1.1e-4 * 0.9 ** x)\n",
    "annealer = LearningRateScheduler(ge_lr)\n",
    "\n",
    "log_dir = os.path.join(log_path, run_name)\n",
    "print('log_dir:' + log_dir)\n",
    "tensorBoard = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53879 samples, validate on 7120 samples\n",
      "0.0015 Epoch 1/100\n",
      "53879/53879 [==============================] - 215s - loss: 4.3613 - acc: 0.0350 - val_loss: 4.8793 - val_acc: 0.0108\n",
      "0.00135 Epoch 2/100\n",
      "53879/53879 [==============================] - 210s - loss: 3.8653 - acc: 0.0753 - val_loss: 4.5622 - val_acc: 0.0397\n",
      "0.0012150000000000002 Epoch 3/100\n",
      "53879/53879 [==============================] - 210s - loss: 3.3620 - acc: 0.1465 - val_loss: 3.2656 - val_acc: 0.1525\n",
      "0.0010935 Epoch 4/100\n",
      "53879/53879 [==============================] - 210s - loss: 2.9534 - acc: 0.2248 - val_loss: 2.7623 - val_acc: 0.2712\n",
      "0.00098415 Epoch 5/100\n",
      "53879/53879 [==============================] - 210s - loss: 2.5844 - acc: 0.3113 - val_loss: 2.3625 - val_acc: 0.3619\n",
      "0.0008857350000000001 Epoch 6/100\n",
      "53879/53879 [==============================] - 211s - loss: 2.2791 - acc: 0.3889 - val_loss: 1.8936 - val_acc: 0.4742\n",
      "0.0007971615000000001 Epoch 7/100\n",
      "53879/53879 [==============================] - 212s - loss: 2.0527 - acc: 0.4468 - val_loss: 1.6398 - val_acc: 0.5427\n",
      "0.0007174453500000002 Epoch 8/100\n",
      "53879/53879 [==============================] - 210s - loss: 1.8706 - acc: 0.4930 - val_loss: 1.6138 - val_acc: 0.5485\n",
      "0.0006457008150000001 Epoch 9/100\n",
      "53879/53879 [==============================] - 209s - loss: 1.7296 - acc: 0.5251 - val_loss: 1.4710 - val_acc: 0.5871\n",
      "0.0005811307335000001 Epoch 10/100\n",
      "53879/53879 [==============================] - 210s - loss: 1.6157 - acc: 0.5565 - val_loss: 1.3574 - val_acc: 0.6124\n",
      "0.0005230176601500002 Epoch 11/100\n",
      "53879/53879 [==============================] - 210s - loss: 1.5207 - acc: 0.5803 - val_loss: 1.3250 - val_acc: 0.6295\n",
      "0.0004707158941350001 Epoch 12/100\n",
      "53879/53879 [==============================] - 210s - loss: 1.4425 - acc: 0.5982 - val_loss: 1.2735 - val_acc: 0.6409\n",
      "0.0004236443047215002 Epoch 13/100\n",
      "53879/53879 [==============================] - 211s - loss: 1.3707 - acc: 0.6162 - val_loss: 1.2010 - val_acc: 0.6615\n",
      "0.0003812798742493501 Epoch 14/100\n",
      "53879/53879 [==============================] - 211s - loss: 1.3014 - acc: 0.6338 - val_loss: 1.2121 - val_acc: 0.6576\n",
      "0.00034315188682441515 Epoch 15/100\n",
      "53879/53879 [==============================] - 211s - loss: 1.2520 - acc: 0.6461 - val_loss: 1.1442 - val_acc: 0.6756\n",
      "0.0003088366981419736 Epoch 16/100\n",
      "53879/53879 [==============================] - 211s - loss: 1.2000 - acc: 0.6595 - val_loss: 1.1747 - val_acc: 0.6667\n",
      "0.00027795302832777627 Epoch 17/100\n",
      "53879/53879 [==============================] - 210s - loss: 1.1497 - acc: 0.6715 - val_loss: 1.1493 - val_acc: 0.6716\n",
      "0.00025015772549499864 Epoch 18/100\n",
      "53879/53879 [==============================] - 210s - loss: 1.1136 - acc: 0.6806 - val_loss: 1.1409 - val_acc: 0.6777\n",
      "0.00022514195294549876 Epoch 19/100\n",
      "53879/53879 [==============================] - 211s - loss: 1.0687 - acc: 0.6914 - val_loss: 1.1172 - val_acc: 0.6876\n",
      "0.00020262775765094893 Epoch 20/100\n",
      "53879/53879 [==============================] - 210s - loss: 1.0431 - acc: 0.6975 - val_loss: 1.1212 - val_acc: 0.6858\n",
      "0.00018236498188585403 Epoch 21/100\n",
      "53879/53879 [==============================] - 210s - loss: 1.0069 - acc: 0.7088 - val_loss: 1.1185 - val_acc: 0.6846\n",
      "0.00016412848369726864 Epoch 22/100\n",
      "53879/53879 [==============================] - 211s - loss: 0.9833 - acc: 0.7123 - val_loss: 1.1114 - val_acc: 0.6910\n",
      "0.00014771563532754177 Epoch 23/100\n",
      "53879/53879 [==============================] - 211s - loss: 0.9480 - acc: 0.7225 - val_loss: 1.1132 - val_acc: 0.6902\n",
      "0.0001329440717947876 Epoch 24/100\n",
      "53879/53879 [==============================] - 210s - loss: 0.9256 - acc: 0.7285 - val_loss: 1.0956 - val_acc: 0.6941\n",
      "0.00011964966461530884 Epoch 25/100\n",
      "53879/53879 [==============================] - 210s - loss: 0.8941 - acc: 0.7361 - val_loss: 1.1119 - val_acc: 0.6927\n",
      "0.00010768469815377795 Epoch 26/100\n",
      "53879/53879 [==============================] - 211s - loss: 0.8755 - acc: 0.7413 - val_loss: 1.1055 - val_acc: 0.6942\n",
      "0.0001 Epoch 27/100\n",
      "53879/53879 [==============================] - 211s - loss: 0.8592 - acc: 0.7443 - val_loss: 1.1162 - val_acc: 0.6940\n",
      "0.0001 Epoch 28/100\n",
      "53879/53879 [==============================] - 211s - loss: 0.8399 - acc: 0.7531 - val_loss: 1.1049 - val_acc: 0.6994\n",
      "0.0001 Epoch 29/100\n",
      "53879/53879 [==============================] - 210s - loss: 0.8214 - acc: 0.7562 - val_loss: 1.1250 - val_acc: 0.6969\n",
      "0.0001 Epoch 30/100\n",
      "53879/53879 [==============================] - 210s - loss: 0.8114 - acc: 0.7586 - val_loss: 1.1065 - val_acc: 0.6983\n",
      "0.0001 Epoch 31/100\n",
      "53879/53879 [==============================] - 210s - loss: 0.7942 - acc: 0.7630 - val_loss: 1.1141 - val_acc: 0.6973\n",
      "0.0001 Epoch 32/100\n",
      "53879/53879 [==============================] - 210s - loss: 0.7848 - acc: 0.7639 - val_loss: 1.1139 - val_acc: 0.6985\n",
      "0.0001 Epoch 33/100\n",
      "53879/53879 [==============================] - 211s - loss: 0.7696 - acc: 0.7666 - val_loss: 1.1128 - val_acc: 0.7025\n",
      "0.0001 Epoch 34/100\n",
      "53879/53879 [==============================] - 210s - loss: 0.7598 - acc: 0.7711 - val_loss: 1.1254 - val_acc: 0.6996\n",
      "0.0001 Epoch 35/100\n",
      "53879/53879 [==============================] - 210s - loss: 0.7430 - acc: 0.7761 - val_loss: 1.1131 - val_acc: 0.7029\n",
      "0.0001 Epoch 36/100\n",
      "53879/53879 [==============================] - 210s - loss: 0.7308 - acc: 0.7790 - val_loss: 1.1278 - val_acc: 0.6993\n",
      "0.0001 Epoch 37/100\n",
      "53879/53879 [==============================] - 211s - loss: 0.7182 - acc: 0.7813 - val_loss: 1.1278 - val_acc: 0.6989\n",
      "0.0001 Epoch 38/100\n",
      "53879/53879 [==============================] - 211s - loss: 0.7045 - acc: 0.7871 - val_loss: 1.1271 - val_acc: 0.7028\n",
      "0.0001 Epoch 39/100\n",
      "53879/53879 [==============================] - 209s - loss: 0.6949 - acc: 0.7891 - val_loss: 1.1383 - val_acc: 0.6993\n",
      "0.0001 Epoch 40/100\n",
      "53879/53879 [==============================] - 209s - loss: 0.6846 - acc: 0.7922 - val_loss: 1.1389 - val_acc: 0.7017\n",
      "0.0001 Epoch 41/100\n",
      "53879/53879 [==============================] - 210s - loss: 0.6793 - acc: 0.7928 - val_loss: 1.1407 - val_acc: 0.7049\n",
      "0.0001 Epoch 42/100\n",
      "53879/53879 [==============================] - 209s - loss: 0.6635 - acc: 0.7986 - val_loss: 1.1338 - val_acc: 0.7052\n",
      "0.0001 Epoch 43/100\n",
      "53879/53879 [==============================] - 209s - loss: 0.6448 - acc: 0.8017 - val_loss: 1.1554 - val_acc: 0.7017\n",
      "0.0001 Epoch 44/100\n",
      "53879/53879 [==============================] - 210s - loss: 0.6452 - acc: 0.8020 - val_loss: 1.1470 - val_acc: 0.7041\n",
      "0.0001 Epoch 45/100\n",
      "53879/53879 [==============================] - 209s - loss: 0.6306 - acc: 0.8066 - val_loss: 1.1496 - val_acc: 0.7056\n",
      "0.0001 Epoch 46/100\n",
      "53879/53879 [==============================] - 209s - loss: 0.6202 - acc: 0.8086 - val_loss: 1.1369 - val_acc: 0.7122\n",
      "0.0001 Epoch 47/100\n",
      "53879/53879 [==============================] - 209s - loss: 0.6001 - acc: 0.8122 - val_loss: 1.1622 - val_acc: 0.7060\n",
      "0.0001 Epoch 48/100\n",
      "53879/53879 [==============================] - 210s - loss: 0.5935 - acc: 0.8166 - val_loss: 1.1603 - val_acc: 0.7052\n",
      "0.0001 Epoch 49/100\n",
      "53879/53879 [==============================] - 210s - loss: 0.5845 - acc: 0.8185 - val_loss: 1.1756 - val_acc: 0.7055\n",
      "0.0001 Epoch 50/100\n",
      "53879/53879 [==============================] - 210s - loss: 0.5724 - acc: 0.8233 - val_loss: 1.1762 - val_acc: 0.7070\n",
      "0.0001 Epoch 51/100\n",
      "53879/53879 [==============================] - 209s - loss: 0.5670 - acc: 0.8225 - val_loss: 1.1872 - val_acc: 0.7051\n",
      "0.0001 Epoch 52/100\n",
      "53879/53879 [==============================] - 209s - loss: 0.5516 - acc: 0.8277 - val_loss: 1.1981 - val_acc: 0.7076\n",
      "0.0001 Epoch 53/100\n",
      "53879/53879 [==============================] - 209s - loss: 0.5407 - acc: 0.8302 - val_loss: 1.2025 - val_acc: 0.7070\n",
      "0.0001 Epoch 54/100\n",
      "53879/53879 [==============================] - 210s - loss: 0.5456 - acc: 0.8299 - val_loss: 1.1984 - val_acc: 0.7013\n",
      "0.0001 Epoch 55/100\n",
      "53879/53879 [==============================] - 210s - loss: 0.5299 - acc: 0.8341 - val_loss: 1.1929 - val_acc: 0.7051\n",
      "0.0001 Epoch 56/100\n",
      "40192/53879 [=====================>........] - ETA: 50s - loss: 0.5153 - acc: 0.8387"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1598\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2273\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = Sequential()\n",
    "# Block 1\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation='relu', padding = 'Same',\n",
    "                 input_shape = (91, 91, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(strides=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "# Block 2\n",
    "# model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(strides=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "# Block 3\n",
    "# model.add(Conv2D(filters = 256, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(filters = 256, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(strides=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "# Block 4\n",
    "# model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(strides=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "# Block 5\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Output\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(80, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = Adam(lr=1e-4), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "hist = model.fit(x_train0, y_train, \n",
    "                 batch_size = 256, \n",
    "                 verbose=1,\n",
    "                 epochs = 100,\n",
    "                 validation_data=(x_val0, y_val), \n",
    "                 callbacks=[annealer, tensorBoard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 1.2017, final accuracy: 0.7065\n"
     ]
    }
   ],
   "source": [
    "final_loss, final_acc = model.evaluate(x_val0, y_val, verbose=0)\n",
    "print(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model.predict(x_val0)\n",
    "print(val_preds.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "print('Val log_loss: {}'.format(log_loss(y_val, val_preds)))\n",
    "val_proba_limited = np.clip(val_preds, 0.005, 0.995)\n",
    "print('Val limited log_loss: {}'.format(log_loss(y_val, val_proba_limited)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(hist.history['loss'], color='b')\n",
    "plt.plot(hist.history['val_loss'], color='r')\n",
    "plt.show()\n",
    "plt.plot(hist.history['acc'], color='b')\n",
    "plt.plot(hist.history['val_acc'], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_name0 = run_name + '_' + str(int(final_acc*10000)).zfill(4)\n",
    "print('run_name: ' + run_name0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveModel(model, run_name):\n",
    "    cwd = os.getcwd()\n",
    "    modelPath = os.path.join(cwd, 'model')\n",
    "    if not os.path.isdir(modelPath):\n",
    "        os.mkdir(modelPath)\n",
    "    weigthsFile = os.path.join(modelPath, run_name + '.h5')\n",
    "    model.save(weigthsFile)\n",
    "saveModel(model, run_name0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
