{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train_NN\n",
    "\n",
    "**Tensorboard**\n",
    "- Input at command: tensorboard --logdir=./log\n",
    "- Input at browser: http://127.0.0.1:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: SceneClassification_Train_NN_20171203_105335\n",
      "model_path: E:\\AIChallenger\\SceneClassification2017\\model\n",
      "feature_pca_file: E:\\AIChallenger\\SceneClassification2017\\model\\feature_pca_SceneClassification_Dim_reduction_20171202_235958.h5\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "project_name = 'SceneClassification'\n",
    "step_name = 'Train_NN'\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "run_name = project_name + '_' + step_name + '_' + time_str\n",
    "print('run_name: ' + run_name)\n",
    "\n",
    "cwd = os.getcwd()\n",
    "model_path = os.path.join(cwd, 'model')\n",
    "feature_pca_file = os.path.join(model_path, 'feature_pca_SceneClassification_Dim_reduction_20171202_235958.h5')\n",
    "print('model_path: ' + model_path)\n",
    "print('feature_pca_file: ' + feature_pca_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00002ff812f48a3df27c321d517a6300ed8da0c3.jpg', '00049a860dca2af378faeb0ee6f435c6063818ef.jpg', '0011a9c9216c3763ffc33641a8ffc975127dc404.jpg', '0045a44cacc7bc9826db9b54d2dcd70b810250f9.jpg', '004b6823145471c6a4ce292e864909fde2d04969.jpg', '0056e4d54eee781117c9d407d03ebf7192126b1f.jpg', '005763f88b25b18ae524b25afcce960403665383.jpg', '005b5444df96e3a155f2a73a8dccc0267e118413.jpg', '005c6ba205a246d0d3c8f73adfd4398b8e483962.jpg', '005de85662d754f98a1476a37b189902800ace91.jpg']\n"
     ]
    }
   ],
   "source": [
    "test_images = os.listdir(os.path.join(cwd, 'input', 'data_test_a', 'test'))\n",
    "print(test_images[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53879, 512)\n",
      "53879\n",
      "(7120, 512)\n",
      "7120\n",
      "(7078, 512)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "with h5py.File(feature_pca_file, 'r') as h:\n",
    "    x_train = np.array(h['train'])\n",
    "    y_train = np.array(h['train_label'])\n",
    "    x_val = np.array(h['val'])\n",
    "    y_val = np.array(h['val_label'])\n",
    "    x_test = np.array(h['test_b'])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(len(y_train))\n",
    "print(x_val.shape)\n",
    "print(len(y_val))\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53879, 512)\n",
      "(53879,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53879, 80)\n",
      "(7120, 80)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=x_train.shape[1:]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(80, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_dir:E:\\AIChallenger\\SceneClassification2017\\model\\SceneClassification_Train_NN_20171203_105335\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "log_path = os.path.join(model_path, run_name)\n",
    "print('log_dir:' + log_path)\n",
    "\n",
    "from keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "# annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x) # Do not why, when add annealer, the net will be divergency\n",
    "tensorBoard = TensorBoard(log_dir=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53879 samples, validate on 7120 samples\n",
      "Epoch 1/200\n",
      "53879/53879 [==============================] - 1s 22us/step - loss: 4.5974 - acc: 0.0206 - val_loss: 4.2593 - val_acc: 0.2145\n",
      "Epoch 2/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 4.2482 - acc: 0.0476 - val_loss: 3.9753 - val_acc: 0.3087\n",
      "Epoch 3/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 3.9336 - acc: 0.1076 - val_loss: 3.2843 - val_acc: 0.3968\n",
      "Epoch 4/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 3.4693 - acc: 0.1906 - val_loss: 2.6054 - val_acc: 0.4791\n",
      "Epoch 5/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 3.0346 - acc: 0.2713 - val_loss: 2.1107 - val_acc: 0.5413\n",
      "Epoch 6/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 2.6935 - acc: 0.3345 - val_loss: 1.7969 - val_acc: 0.5848\n",
      "Epoch 7/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 2.4433 - acc: 0.3873 - val_loss: 1.6064 - val_acc: 0.6121\n",
      "Epoch 8/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 2.2703 - acc: 0.4233 - val_loss: 1.4693 - val_acc: 0.6358\n",
      "Epoch 9/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 2.1342 - acc: 0.4496 - val_loss: 1.3799 - val_acc: 0.6497\n",
      "Epoch 10/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 2.0212 - acc: 0.4783 - val_loss: 1.3035 - val_acc: 0.6596\n",
      "Epoch 11/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.9468 - acc: 0.4976 - val_loss: 1.2497 - val_acc: 0.6713\n",
      "Epoch 12/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.8723 - acc: 0.5134 - val_loss: 1.2064 - val_acc: 0.6765\n",
      "Epoch 13/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.8272 - acc: 0.5242 - val_loss: 1.1713 - val_acc: 0.6844\n",
      "Epoch 14/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.7725 - acc: 0.5373 - val_loss: 1.1418 - val_acc: 0.6910\n",
      "Epoch 15/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.7325 - acc: 0.5473 - val_loss: 1.1141 - val_acc: 0.6976\n",
      "Epoch 16/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.6851 - acc: 0.5576 - val_loss: 1.0888 - val_acc: 0.7037\n",
      "Epoch 17/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.6384 - acc: 0.5688 - val_loss: 1.0646 - val_acc: 0.7090\n",
      "Epoch 18/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.6176 - acc: 0.5744 - val_loss: 1.0492 - val_acc: 0.7133\n",
      "Epoch 19/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.5849 - acc: 0.5822 - val_loss: 1.0341 - val_acc: 0.7174\n",
      "Epoch 20/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.5662 - acc: 0.5862 - val_loss: 1.0179 - val_acc: 0.7205\n",
      "Epoch 21/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.5342 - acc: 0.5946 - val_loss: 1.0073 - val_acc: 0.7244\n",
      "Epoch 22/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.5133 - acc: 0.6015 - val_loss: 0.9962 - val_acc: 0.7239\n",
      "Epoch 23/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.4874 - acc: 0.6044 - val_loss: 0.9831 - val_acc: 0.7284\n",
      "Epoch 24/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.4687 - acc: 0.6069 - val_loss: 0.9729 - val_acc: 0.7322\n",
      "Epoch 25/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.4502 - acc: 0.6143 - val_loss: 0.9659 - val_acc: 0.7320\n",
      "Epoch 26/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.4318 - acc: 0.6182 - val_loss: 0.9559 - val_acc: 0.7351\n",
      "Epoch 27/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.4186 - acc: 0.6225 - val_loss: 0.9486 - val_acc: 0.7383\n",
      "Epoch 28/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.4053 - acc: 0.6249 - val_loss: 0.9407 - val_acc: 0.7393\n",
      "Epoch 29/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.3811 - acc: 0.6306 - val_loss: 0.9332 - val_acc: 0.7393\n",
      "Epoch 30/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.3748 - acc: 0.6356 - val_loss: 0.9279 - val_acc: 0.7416\n",
      "Epoch 31/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.3625 - acc: 0.6379 - val_loss: 0.9204 - val_acc: 0.7426\n",
      "Epoch 32/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.3498 - acc: 0.6387 - val_loss: 0.9148 - val_acc: 0.7445\n",
      "Epoch 33/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.3372 - acc: 0.6425 - val_loss: 0.9090 - val_acc: 0.7451\n",
      "Epoch 34/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.3213 - acc: 0.6464 - val_loss: 0.9039 - val_acc: 0.7445\n",
      "Epoch 35/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.3051 - acc: 0.6468 - val_loss: 0.8968 - val_acc: 0.7472\n",
      "Epoch 36/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.2945 - acc: 0.6508 - val_loss: 0.8914 - val_acc: 0.7469\n",
      "Epoch 37/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.2899 - acc: 0.6527 - val_loss: 0.8889 - val_acc: 0.7499\n",
      "Epoch 38/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.2816 - acc: 0.6534 - val_loss: 0.8846 - val_acc: 0.7503\n",
      "Epoch 39/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.2620 - acc: 0.6613 - val_loss: 0.8786 - val_acc: 0.7507\n",
      "Epoch 40/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.2522 - acc: 0.6629 - val_loss: 0.8752 - val_acc: 0.7511\n",
      "Epoch 41/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.2516 - acc: 0.6639 - val_loss: 0.8720 - val_acc: 0.7541\n",
      "Epoch 42/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.2404 - acc: 0.6666 - val_loss: 0.8680 - val_acc: 0.7538\n",
      "Epoch 43/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.2232 - acc: 0.6701 - val_loss: 0.8654 - val_acc: 0.7567\n",
      "Epoch 44/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.2257 - acc: 0.6706 - val_loss: 0.8615 - val_acc: 0.7569\n",
      "Epoch 45/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.2136 - acc: 0.6728 - val_loss: 0.8575 - val_acc: 0.7580\n",
      "Epoch 46/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.2048 - acc: 0.6720 - val_loss: 0.8551 - val_acc: 0.7576\n",
      "Epoch 47/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.2012 - acc: 0.6757 - val_loss: 0.8521 - val_acc: 0.7584\n",
      "Epoch 48/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.1913 - acc: 0.6789 - val_loss: 0.8504 - val_acc: 0.7600\n",
      "Epoch 49/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.1856 - acc: 0.6793 - val_loss: 0.8477 - val_acc: 0.7597\n",
      "Epoch 50/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.1784 - acc: 0.6828 - val_loss: 0.8452 - val_acc: 0.7608\n",
      "Epoch 51/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.1687 - acc: 0.6832 - val_loss: 0.8444 - val_acc: 0.7610\n",
      "Epoch 52/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.1599 - acc: 0.6848 - val_loss: 0.8404 - val_acc: 0.7614\n",
      "Epoch 53/200\n",
      "53879/53879 [==============================] - 1s 16us/step - loss: 1.1594 - acc: 0.6841 - val_loss: 0.8387 - val_acc: 0.7638\n",
      "Epoch 54/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.1428 - acc: 0.6881 - val_loss: 0.8377 - val_acc: 0.7628\n",
      "Epoch 55/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.1426 - acc: 0.6885 - val_loss: 0.8350 - val_acc: 0.7642\n",
      "Epoch 56/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.1426 - acc: 0.6877 - val_loss: 0.8340 - val_acc: 0.7642\n",
      "Epoch 57/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.1337 - acc: 0.6922 - val_loss: 0.8316 - val_acc: 0.7640\n",
      "Epoch 58/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.1216 - acc: 0.6943 - val_loss: 0.8288 - val_acc: 0.7645\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.1170 - acc: 0.6939 - val_loss: 0.8285 - val_acc: 0.7653\n",
      "Epoch 60/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.1134 - acc: 0.6952 - val_loss: 0.8262 - val_acc: 0.7643\n",
      "Epoch 61/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.1107 - acc: 0.6951 - val_loss: 0.8246 - val_acc: 0.7650\n",
      "Epoch 62/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.1030 - acc: 0.6983 - val_loss: 0.8246 - val_acc: 0.7649\n",
      "Epoch 63/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.0886 - acc: 0.7003 - val_loss: 0.8216 - val_acc: 0.7647\n",
      "Epoch 64/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.0892 - acc: 0.7010 - val_loss: 0.8212 - val_acc: 0.7676\n",
      "Epoch 65/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.0841 - acc: 0.7008 - val_loss: 0.8185 - val_acc: 0.7656\n",
      "Epoch 66/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.0797 - acc: 0.7024 - val_loss: 0.8174 - val_acc: 0.7676\n",
      "Epoch 67/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.0747 - acc: 0.7048 - val_loss: 0.8159 - val_acc: 0.7683\n",
      "Epoch 68/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.0717 - acc: 0.7050 - val_loss: 0.8152 - val_acc: 0.7656\n",
      "Epoch 69/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.0704 - acc: 0.7045 - val_loss: 0.8139 - val_acc: 0.7653\n",
      "Epoch 70/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.0569 - acc: 0.7087 - val_loss: 0.8123 - val_acc: 0.7670\n",
      "Epoch 71/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.0537 - acc: 0.7092 - val_loss: 0.8106 - val_acc: 0.7671\n",
      "Epoch 72/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.0510 - acc: 0.7103 - val_loss: 0.8091 - val_acc: 0.7669\n",
      "Epoch 73/200\n",
      "53879/53879 [==============================] - 1s 14us/step - loss: 1.0468 - acc: 0.7102 - val_loss: 0.8084 - val_acc: 0.7697\n",
      "Epoch 74/200\n",
      "53879/53879 [==============================] - 1s 14us/step - loss: 1.0392 - acc: 0.7133 - val_loss: 0.8080 - val_acc: 0.7685\n",
      "Epoch 75/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.0307 - acc: 0.7134 - val_loss: 0.8072 - val_acc: 0.7680\n",
      "Epoch 76/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.0295 - acc: 0.7166 - val_loss: 0.8059 - val_acc: 0.7691\n",
      "Epoch 77/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.0298 - acc: 0.7182 - val_loss: 0.8053 - val_acc: 0.7685\n",
      "Epoch 78/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.0258 - acc: 0.7161 - val_loss: 0.8045 - val_acc: 0.7690\n",
      "Epoch 79/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.0157 - acc: 0.7193 - val_loss: 0.8025 - val_acc: 0.7687\n",
      "Epoch 80/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.0084 - acc: 0.7188 - val_loss: 0.8036 - val_acc: 0.7690\n",
      "Epoch 81/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.0093 - acc: 0.7211 - val_loss: 0.8029 - val_acc: 0.7697\n",
      "Epoch 82/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.0062 - acc: 0.7205 - val_loss: 0.8005 - val_acc: 0.7702\n",
      "Epoch 83/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 1.0012 - acc: 0.7214 - val_loss: 0.8006 - val_acc: 0.7695\n",
      "Epoch 84/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9978 - acc: 0.7236 - val_loss: 0.7997 - val_acc: 0.7688\n",
      "Epoch 85/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9940 - acc: 0.7226 - val_loss: 0.7982 - val_acc: 0.7706\n",
      "Epoch 86/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9903 - acc: 0.7245 - val_loss: 0.7964 - val_acc: 0.7719\n",
      "Epoch 87/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9870 - acc: 0.7258 - val_loss: 0.7957 - val_acc: 0.7718\n",
      "Epoch 88/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9812 - acc: 0.7266 - val_loss: 0.7968 - val_acc: 0.7728\n",
      "Epoch 89/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9728 - acc: 0.7286 - val_loss: 0.7951 - val_acc: 0.7730\n",
      "Epoch 90/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9751 - acc: 0.7280 - val_loss: 0.7953 - val_acc: 0.7715\n",
      "Epoch 91/200\n",
      "53879/53879 [==============================] - 1s 14us/step - loss: 0.9684 - acc: 0.7289 - val_loss: 0.7965 - val_acc: 0.7723\n",
      "Epoch 92/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9709 - acc: 0.7297 - val_loss: 0.7965 - val_acc: 0.7732\n",
      "Epoch 93/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9584 - acc: 0.7314 - val_loss: 0.7946 - val_acc: 0.7739\n",
      "Epoch 94/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9672 - acc: 0.7289 - val_loss: 0.7953 - val_acc: 0.7735\n",
      "Epoch 95/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9596 - acc: 0.7329 - val_loss: 0.7940 - val_acc: 0.7729\n",
      "Epoch 96/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9526 - acc: 0.7339 - val_loss: 0.7959 - val_acc: 0.7728\n",
      "Epoch 97/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9452 - acc: 0.7360 - val_loss: 0.7946 - val_acc: 0.7730\n",
      "Epoch 98/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9462 - acc: 0.7342 - val_loss: 0.7948 - val_acc: 0.7730\n",
      "Epoch 99/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9447 - acc: 0.7344 - val_loss: 0.7944 - val_acc: 0.7747\n",
      "Epoch 100/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9347 - acc: 0.7353 - val_loss: 0.7949 - val_acc: 0.7751\n",
      "Epoch 101/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9363 - acc: 0.7369 - val_loss: 0.7937 - val_acc: 0.7729\n",
      "Epoch 102/200\n",
      "53879/53879 [==============================] - 1s 14us/step - loss: 0.9398 - acc: 0.7359 - val_loss: 0.7943 - val_acc: 0.7742\n",
      "Epoch 103/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9305 - acc: 0.7375 - val_loss: 0.7927 - val_acc: 0.7736\n",
      "Epoch 104/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9314 - acc: 0.7366 - val_loss: 0.7926 - val_acc: 0.7736\n",
      "Epoch 105/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9170 - acc: 0.7409 - val_loss: 0.7923 - val_acc: 0.7729\n",
      "Epoch 106/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9146 - acc: 0.7423 - val_loss: 0.7906 - val_acc: 0.7721\n",
      "Epoch 107/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9206 - acc: 0.7405 - val_loss: 0.7906 - val_acc: 0.7706\n",
      "Epoch 108/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9175 - acc: 0.7421 - val_loss: 0.7900 - val_acc: 0.7732\n",
      "Epoch 109/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9117 - acc: 0.7441 - val_loss: 0.7911 - val_acc: 0.7732\n",
      "Epoch 110/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9057 - acc: 0.7443 - val_loss: 0.7908 - val_acc: 0.7735\n",
      "Epoch 111/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9116 - acc: 0.7418 - val_loss: 0.7914 - val_acc: 0.7736\n",
      "Epoch 112/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9023 - acc: 0.7451 - val_loss: 0.7895 - val_acc: 0.7735\n",
      "Epoch 113/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.9001 - acc: 0.7461 - val_loss: 0.7887 - val_acc: 0.7746\n",
      "Epoch 114/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8996 - acc: 0.7450 - val_loss: 0.7889 - val_acc: 0.7744\n",
      "Epoch 115/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8981 - acc: 0.7473 - val_loss: 0.7886 - val_acc: 0.7737\n",
      "Epoch 116/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8920 - acc: 0.7481 - val_loss: 0.7896 - val_acc: 0.7740\n",
      "Epoch 117/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8836 - acc: 0.7499 - val_loss: 0.7904 - val_acc: 0.7744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8848 - acc: 0.7491 - val_loss: 0.7870 - val_acc: 0.7754\n",
      "Epoch 119/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8786 - acc: 0.7507 - val_loss: 0.7883 - val_acc: 0.7746\n",
      "Epoch 120/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8790 - acc: 0.7501 - val_loss: 0.7864 - val_acc: 0.7740\n",
      "Epoch 121/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8740 - acc: 0.7527 - val_loss: 0.7875 - val_acc: 0.7746\n",
      "Epoch 122/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8702 - acc: 0.7532 - val_loss: 0.7871 - val_acc: 0.7744\n",
      "Epoch 123/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8705 - acc: 0.7537 - val_loss: 0.7876 - val_acc: 0.7758\n",
      "Epoch 124/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8612 - acc: 0.7533 - val_loss: 0.7883 - val_acc: 0.7770\n",
      "Epoch 125/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8641 - acc: 0.7543 - val_loss: 0.7891 - val_acc: 0.7764\n",
      "Epoch 126/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8578 - acc: 0.7537 - val_loss: 0.7884 - val_acc: 0.7760\n",
      "Epoch 127/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8636 - acc: 0.7553 - val_loss: 0.7886 - val_acc: 0.7753\n",
      "Epoch 128/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8596 - acc: 0.7554 - val_loss: 0.7889 - val_acc: 0.7757\n",
      "Epoch 129/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8531 - acc: 0.7572 - val_loss: 0.7872 - val_acc: 0.7743\n",
      "Epoch 130/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8490 - acc: 0.7569 - val_loss: 0.7894 - val_acc: 0.7761\n",
      "Epoch 131/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8486 - acc: 0.7590 - val_loss: 0.7887 - val_acc: 0.7747\n",
      "Epoch 132/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8436 - acc: 0.7590 - val_loss: 0.7914 - val_acc: 0.7751\n",
      "Epoch 133/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8404 - acc: 0.7593 - val_loss: 0.7908 - val_acc: 0.7751\n",
      "Epoch 134/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8382 - acc: 0.7601 - val_loss: 0.7912 - val_acc: 0.7733\n",
      "Epoch 135/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8355 - acc: 0.7597 - val_loss: 0.7913 - val_acc: 0.7744\n",
      "Epoch 136/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8308 - acc: 0.7617 - val_loss: 0.7939 - val_acc: 0.7756\n",
      "Epoch 137/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8381 - acc: 0.7577 - val_loss: 0.7912 - val_acc: 0.7757\n",
      "Epoch 138/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8281 - acc: 0.7640 - val_loss: 0.7919 - val_acc: 0.7758\n",
      "Epoch 139/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8260 - acc: 0.7617 - val_loss: 0.7919 - val_acc: 0.7771\n",
      "Epoch 140/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8217 - acc: 0.7643 - val_loss: 0.7902 - val_acc: 0.7765\n",
      "Epoch 141/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8247 - acc: 0.7638 - val_loss: 0.7923 - val_acc: 0.7749\n",
      "Epoch 142/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8203 - acc: 0.7645 - val_loss: 0.7924 - val_acc: 0.7765\n",
      "Epoch 143/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8188 - acc: 0.7640 - val_loss: 0.7918 - val_acc: 0.7746\n",
      "Epoch 144/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8110 - acc: 0.7671 - val_loss: 0.7919 - val_acc: 0.7740\n",
      "Epoch 145/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8100 - acc: 0.7688 - val_loss: 0.7916 - val_acc: 0.7778\n",
      "Epoch 146/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8120 - acc: 0.7676 - val_loss: 0.7912 - val_acc: 0.7777\n",
      "Epoch 147/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8108 - acc: 0.7662 - val_loss: 0.7926 - val_acc: 0.7768\n",
      "Epoch 148/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8023 - acc: 0.7688 - val_loss: 0.7925 - val_acc: 0.7772\n",
      "Epoch 149/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.8041 - acc: 0.7692 - val_loss: 0.7930 - val_acc: 0.7778\n",
      "Epoch 150/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7949 - acc: 0.7694 - val_loss: 0.7934 - val_acc: 0.7774\n",
      "Epoch 151/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7956 - acc: 0.7701 - val_loss: 0.7917 - val_acc: 0.7775\n",
      "Epoch 152/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7928 - acc: 0.7716 - val_loss: 0.7924 - val_acc: 0.7784\n",
      "Epoch 153/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7919 - acc: 0.7713 - val_loss: 0.7931 - val_acc: 0.7778\n",
      "Epoch 154/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7883 - acc: 0.7702 - val_loss: 0.7942 - val_acc: 0.7775\n",
      "Epoch 155/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7853 - acc: 0.7716 - val_loss: 0.7916 - val_acc: 0.7778\n",
      "Epoch 156/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7893 - acc: 0.7726 - val_loss: 0.7944 - val_acc: 0.7778\n",
      "Epoch 157/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7800 - acc: 0.7743 - val_loss: 0.7937 - val_acc: 0.7779\n",
      "Epoch 158/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7795 - acc: 0.7723 - val_loss: 0.7955 - val_acc: 0.7768\n",
      "Epoch 159/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7787 - acc: 0.7736 - val_loss: 0.7943 - val_acc: 0.7778\n",
      "Epoch 160/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7810 - acc: 0.7737 - val_loss: 0.7941 - val_acc: 0.7782\n",
      "Epoch 161/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7772 - acc: 0.7738 - val_loss: 0.7949 - val_acc: 0.7771\n",
      "Epoch 162/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7686 - acc: 0.7767 - val_loss: 0.7951 - val_acc: 0.7775\n",
      "Epoch 163/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7662 - acc: 0.7765 - val_loss: 0.7947 - val_acc: 0.7785\n",
      "Epoch 164/200\n",
      "53879/53879 [==============================] - ETA: 0s - loss: 0.7604 - acc: 0.777 - 1s 14us/step - loss: 0.7606 - acc: 0.7777 - val_loss: 0.7953 - val_acc: 0.7782\n",
      "Epoch 165/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7694 - acc: 0.7778 - val_loss: 0.7955 - val_acc: 0.7788\n",
      "Epoch 166/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7605 - acc: 0.7799 - val_loss: 0.7968 - val_acc: 0.7792\n",
      "Epoch 167/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7611 - acc: 0.7783 - val_loss: 0.7966 - val_acc: 0.7799\n",
      "Epoch 168/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7608 - acc: 0.7791 - val_loss: 0.7973 - val_acc: 0.7792\n",
      "Epoch 169/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7552 - acc: 0.7797 - val_loss: 0.7975 - val_acc: 0.7781\n",
      "Epoch 170/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7533 - acc: 0.7787 - val_loss: 0.7972 - val_acc: 0.7778\n",
      "Epoch 171/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7507 - acc: 0.7818 - val_loss: 0.7965 - val_acc: 0.7774\n",
      "Epoch 172/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7534 - acc: 0.7811 - val_loss: 0.7978 - val_acc: 0.7772\n",
      "Epoch 173/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7463 - acc: 0.7832 - val_loss: 0.8004 - val_acc: 0.7774\n",
      "Epoch 174/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7475 - acc: 0.7816 - val_loss: 0.7977 - val_acc: 0.7782\n",
      "Epoch 175/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7502 - acc: 0.7809 - val_loss: 0.7985 - val_acc: 0.7777\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7426 - acc: 0.7813 - val_loss: 0.7992 - val_acc: 0.7788\n",
      "Epoch 177/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7389 - acc: 0.7847 - val_loss: 0.7979 - val_acc: 0.7803\n",
      "Epoch 178/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7421 - acc: 0.7815 - val_loss: 0.7990 - val_acc: 0.7788\n",
      "Epoch 179/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7386 - acc: 0.7843 - val_loss: 0.8009 - val_acc: 0.7791\n",
      "Epoch 180/200\n",
      "53879/53879 [==============================] - 1s 14us/step - loss: 0.7350 - acc: 0.7846 - val_loss: 0.7994 - val_acc: 0.7789\n",
      "Epoch 181/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7290 - acc: 0.7869 - val_loss: 0.8002 - val_acc: 0.7781\n",
      "Epoch 182/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7288 - acc: 0.7854 - val_loss: 0.8018 - val_acc: 0.7777\n",
      "Epoch 183/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7294 - acc: 0.7864 - val_loss: 0.8033 - val_acc: 0.7774\n",
      "Epoch 184/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7298 - acc: 0.7871 - val_loss: 0.8032 - val_acc: 0.7794\n",
      "Epoch 185/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7267 - acc: 0.7869 - val_loss: 0.8042 - val_acc: 0.7768\n",
      "Epoch 186/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7186 - acc: 0.7904 - val_loss: 0.8040 - val_acc: 0.7799\n",
      "Epoch 187/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7170 - acc: 0.7902 - val_loss: 0.8041 - val_acc: 0.7796\n",
      "Epoch 188/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7208 - acc: 0.7874 - val_loss: 0.8037 - val_acc: 0.7787\n",
      "Epoch 189/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7157 - acc: 0.7894 - val_loss: 0.8029 - val_acc: 0.7787\n",
      "Epoch 190/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7159 - acc: 0.7882 - val_loss: 0.8029 - val_acc: 0.7799\n",
      "Epoch 191/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7103 - acc: 0.7906 - val_loss: 0.8044 - val_acc: 0.7782\n",
      "Epoch 192/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7042 - acc: 0.7921 - val_loss: 0.8036 - val_acc: 0.7794\n",
      "Epoch 193/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7170 - acc: 0.7899 - val_loss: 0.8035 - val_acc: 0.7785\n",
      "Epoch 194/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7004 - acc: 0.7946 - val_loss: 0.8041 - val_acc: 0.7777\n",
      "Epoch 195/200\n",
      "53879/53879 [==============================] - 1s 14us/step - loss: 0.7017 - acc: 0.7925 - val_loss: 0.8033 - val_acc: 0.7784\n",
      "Epoch 196/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7013 - acc: 0.7933 - val_loss: 0.8040 - val_acc: 0.7777\n",
      "Epoch 197/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.7018 - acc: 0.7919 - val_loss: 0.8039 - val_acc: 0.7775\n",
      "Epoch 198/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.6978 - acc: 0.7949 - val_loss: 0.8037 - val_acc: 0.7760\n",
      "Epoch 199/200\n",
      "53879/53879 [==============================] - 1s 15us/step - loss: 0.6938 - acc: 0.7954 - val_loss: 0.8037 - val_acc: 0.7778\n",
      "Epoch 200/200\n",
      "53879/53879 [==============================] - 1s 16us/step - loss: 0.6942 - acc: 0.7944 - val_loss: 0.8033 - val_acc: 0.7779\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train,\n",
    "                 batch_size=1024,\n",
    "                 epochs=200, #Increase this when not on Kaggle kernel\n",
    "                 verbose=1,  #1 for ETA, 0 for silent\n",
    "                 validation_data=(x_val, y_val), \n",
    "                 callbacks=[tensorBoard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 0.8033, final accuracy: 0.7779\n"
     ]
    }
   ],
   "source": [
    "final_loss, final_acc = model.evaluate(x_val, y_val, verbose=0)\n",
    "print(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7120, 80)\n",
      "(7120, 80)\n"
     ]
    }
   ],
   "source": [
    "val_preds = model.predict(x_val)\n",
    "print(val_preds.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val log_loss: 0.8040738686090223\n",
      "Val limited log_loss: 1.0569464006785596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "print('Val log_loss: {}'.format(log_loss(y_val, val_preds)))\n",
    "val_proba_limited = np.clip(val_preds, 0.005, 0.995)\n",
    "print('Val limited log_loss: {}'.format(log_loss(y_val, val_proba_limited)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCncRkRqkcBcRqUEKdxGRGqRwFxGpQf8f82o8Q9HivmYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4352038470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4353217cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(hist.history['loss'], color='b')\n",
    "plt.plot(hist.history['val_loss'], color='r')\n",
    "plt.show()\n",
    "plt.plot(hist.history['acc'], color='b')\n",
    "plt.plot(hist.history['val_acc'], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: SceneClassification_Train_NN_20171203_105335_7779\n"
     ]
    }
   ],
   "source": [
    "run_name0 = run_name + '_' + str(int(final_acc*10000))\n",
    "print('run_name: ' + run_name0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveModel(model, run_name):\n",
    "    cwd = os.getcwd()\n",
    "    modelPath = os.path.join(cwd, 'model')\n",
    "    if not os.path.isdir(modelPath):\n",
    "        os.mkdir(modelPath)\n",
    "    weigthsFile = os.path.join(modelPath, run_name + '.h5')\n",
    "    model.save(weigthsFile)\n",
    "saveModel(model, run_name0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SceneClassification_Train_NN_20171203_105335_7779\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "print(run_name0)\n",
    "print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
