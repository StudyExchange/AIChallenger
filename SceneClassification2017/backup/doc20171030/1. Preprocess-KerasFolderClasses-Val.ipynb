{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scene Classification-Val\n",
    "## 1. Preprocess-KerasFolderClasses\n",
    "- Import pkg\n",
    "- Extract zip file\n",
    "- Preview \"scene_classes.csv\"\n",
    "- Preview \"scene_{0}_annotations_20170904.json\"\n",
    "- Test the image and pickle function\n",
    "- Split data into serval pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part need jupyter notebook start with \"jupyter notebook --NotebookApp.iopub_data_rate_limit=1000000000\" (https://github.com/jupyter/notebook/issues/2287)\n",
    "\n",
    "Reference:\n",
    "- https://challenger.ai/competitions\n",
    "- https://github.com/jupyter/notebook/issues/2287"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "import os\n",
    "import zipfile\n",
    "import math\n",
    "from time import time\n",
    "from IPython.display import display\n",
    "import pdb\n",
    "import json\n",
    "from PIL import Image\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input\\data_validation\n",
      "input\\ai_challenger_scene_validation_20170908.zip\n",
      "input\\ai_challenger_scene_validation_20170908\n",
      "input\\ai_challenger_scene_validation_20170908\\scene_validation_images_20170908\n",
      "input\\ai_challenger_scene_validation_20170908\\scene_classes.csv\n",
      "input\\ai_challenger_scene_validation_20170908\\scene_validation_annotations_20170908.json\n"
     ]
    }
   ],
   "source": [
    "input_path = 'input'\n",
    "datasetName = 'validation'\n",
    "date = '20170908'\n",
    "\n",
    "datasetFolder = input_path + '\\\\data_{0}'.format(datasetName)\n",
    "zip_path = input_path + '\\\\ai_challenger_scene_{0}_{1}.zip'.format(datasetName, date)\n",
    "extract_path = input_path + '\\\\ai_challenger_scene_{0}_{1}'.format(datasetName, date)\n",
    "image_path = extract_path + '\\\\scene_{0}_images_{1}'.format(datasetName, date)\n",
    "scene_classes_path = extract_path + '\\\\scene_classes.csv'\n",
    "scene_annotations_path = extract_path + '\\\\scene_{0}_annotations_{1}.json'.format(datasetName, date)\n",
    "\n",
    "print(input_path)\n",
    "print(datasetFolder)\n",
    "print(zip_path)\n",
    "print(extract_path)\n",
    "print(image_path)\n",
    "print(scene_classes_path)\n",
    "print(scene_annotations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(extract_path):\n",
    "    with zipfile.ZipFile(zip_path) as file:\n",
    "        for name in file.namelist():\n",
    "            file.extract(name, input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview \"scene_classes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>航站楼</td>\n",
       "      <td>airport_terminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>停机坪</td>\n",
       "      <td>landing_field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>机舱</td>\n",
       "      <td>airplane_cabin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>游乐场</td>\n",
       "      <td>amusement_park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>冰场</td>\n",
       "      <td>skating_rink</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1                 2\n",
       "0  0  航站楼  airport_terminal\n",
       "1  1  停机坪     landing_field\n",
       "2  2   机舱    airplane_cabin\n",
       "3  3  游乐场    amusement_park\n",
       "4  4   冰场      skating_rink"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scene_classes = pd.read_csv(scene_classes_path, header=None)\n",
    "display(scene_classes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airport_terminal\n"
     ]
    }
   ],
   "source": [
    "def get_scene_name(lable_number, scene_classes_path):\n",
    "    scene_classes = pd.read_csv(scene_classes_path, header=None)\n",
    "    return scene_classes.loc[lable_number, 2]\n",
    "print(get_scene_name(0, scene_classes_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview \"scene_{0}_annotations_20170904.json\"\n",
    "\n",
    "**This part need jupyter notebook start with \"jupyter notebook --NotebookApp.iopub_data_rate_limit=1000000000\"**\n",
    "https://github.com/jupyter/notebook/issues/2287"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(scene_annotations_path, 'r', encoding='utf-8') as file:\n",
    "    content = ''\n",
    "    for line in file:\n",
    "        content = content + line\n",
    "scene_annotations = json.loads(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene_validation_annotations.type: %<class 'list'>\n",
      "scene_validation_annotations.shape: %7120\n",
      "{'image_id': '0c58107693263d32551209512d858246e925fe29.jpg', 'label_id': '18', 'image_url': 'http://m4.biz.itc.cn/pic/new/n/31/90/Img7919031_n.jpg'}\n",
      "label_id[0]:\t18\n",
      "image_id[0]:\t0c58107693263d32551209512d858246e925fe29.jpg\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "#We get a list\n",
    "print('scene_{0}_annotations.type: %{1}'.format(datasetName, type(scene_annotations)))\n",
    "print('scene_{0}_annotations.shape: %{1}'.format(datasetName, len(scene_annotations)))\n",
    "order = 0\n",
    "print(scene_annotations[order])\n",
    "print('label_id[{0}]:\\t{1}'.format(order, scene_annotations[order]['label_id']))\n",
    "print('image_id[{0}]:\\t{1}'.format(order, scene_annotations[order]['image_id']))\n",
    "print(type(scene_annotations[order]['label_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from  shutil import copy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\\data_validation\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(datasetFolder):\n",
    "    os.mkdir(datasetFolder)\n",
    "print(datasetFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\SceneClassification\n",
      "['class-00', 'class-01', 'class-02', 'class-03', 'class-04', 'class-05', 'class-06', 'class-07', 'class-08', 'class-09', 'class-10', 'class-11', 'class-12', 'class-13', 'class-14', 'class-15', 'class-16', 'class-17', 'class-18', 'class-19', 'class-20', 'class-21', 'class-22', 'class-23', 'class-24', 'class-25', 'class-26', 'class-27', 'class-28', 'class-29', 'class-30', 'class-31', 'class-32', 'class-33', 'class-34', 'class-35', 'class-36', 'class-37', 'class-38', 'class-39', 'class-40', 'class-41', 'class-42', 'class-43', 'class-44', 'class-45', 'class-46', 'class-47', 'class-48', 'class-49', 'class-50', 'class-51', 'class-52', 'class-53', 'class-54', 'class-55', 'class-56', 'class-57', 'class-58', 'class-59', 'class-60', 'class-61', 'class-62', 'class-63', 'class-64', 'class-65', 'class-66', 'class-67', 'class-68', 'class-69', 'class-70', 'class-71', 'class-72', 'class-73', 'class-74', 'class-75', 'class-76', 'class-77', 'class-78', 'class-79']\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "length = len(scene_annotations)\n",
    "# length = 2\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "# Create class folder first, then copy files into folders\n",
    "for i in range(80):\n",
    "    class_dir = os.path.join(cwd, datasetFolder + '\\\\class-{0}'.format(str(i).zfill(2)))\n",
    "    if not os.path.isdir(class_dir):\n",
    "        os.mkdir(class_dir)\n",
    "        \n",
    "# print(os.listdir(os.path.join(cwd, datasetFolder)))\n",
    "print(sorted(os.listdir(os.path.join(cwd, datasetFolder))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(length):\n",
    "    fileName = image_path + '/' + scene_annotations[i]['image_id']\n",
    "#     print(fileName)\n",
    "    trainDir = os.path.join(cwd, datasetFolder + '\\\\class-{0}'.format(str(scene_annotations[i]['label_id']).zfill(2)))\n",
    "#     print(trainDir)\n",
    "    \n",
    "    copy2(fileName, trainDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import os,sys\n",
    "# cwd = os.getcwd()\n",
    "# train_path = os.path.join(cwd, 'input\\\\train_data')\n",
    "# folder_names=os.listdir(train_path)\n",
    "# print(folder_names)\n",
    "# for folder in folder_names:\n",
    "#     subfolder = os.path.join(train_path, folder)\n",
    "#     print(subfolder)\n",
    "#     filenames = os.listdir(subfolder)\n",
    "#     count = 1\n",
    "#     for file in filenames:\n",
    "#         old_name = subfolder + '\\\\' + file\n",
    "#         new_name = subfolder + '\\\\' + str(count) + '.jpg'\n",
    "#         print(old_name)\n",
    "#         print(new_name)\n",
    "        \n",
    "#         count=count+1\n",
    "#         os.rename(old_name, new_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
