{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Feature_extraction_Use_InceptionResNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "1. https://github.com/ypwhs/dogs_vs_cats\n",
    "2. https://www.kaggle.com/yangpeiwen/keras-inception-xception-0-47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Import pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import time\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.applications import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(MODEL, image_size, batch_size=1, lambda_func=None):\n",
    "    print('{0} start.'.format(MODEL.__name__))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        print(lambda_func.__name__)\n",
    "        x = Lambda(lambda_func)(x)\n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet', include_top=False)\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    data_train_path = os.path.join(cwd, 'input', 'data_train')\n",
    "    data_val_path = os.path.join(cwd, 'input', 'data_validation')\n",
    "    data_test_path  = os.path.join(cwd, 'input', 'data_test_a')\n",
    "    \n",
    "    gen = ImageDataGenerator()\n",
    "#     gen = ImageDataGenerator(zoom_range = 0.1,\n",
    "#                             height_shift_range = 0.1,\n",
    "#                             width_shift_range = 0.1,\n",
    "#                             rotation_range = 10)\n",
    "    train_generator = gen.flow_from_directory(data_train_path, image_size, shuffle=False, \n",
    "                                              batch_size=batch_size)\n",
    "    val_generator  = gen.flow_from_directory(data_val_path,  image_size, shuffle=False, \n",
    "                                              batch_size=batch_size)\n",
    "    test_generator  = gen.flow_from_directory(data_test_path,  image_size, shuffle=False, \n",
    "                                              batch_size=batch_size)\n",
    "    \n",
    "    train = model.predict_generator(train_generator, verbose=1, steps=53879)\n",
    "    val = model.predict_generator(val_generator, verbose=1, steps=7120)\n",
    "    test = model.predict_generator(test_generator, verbose=1, steps=7040)\n",
    "#     train = model.predict_generator(train_generator, verbose=1, steps=10)\n",
    "#     val = model.predict_generator(val_generator, verbose=1, steps=10)\n",
    "#     test = model.predict_generator(test_generator, verbose=1, steps=10)\n",
    "#     print(test_generator.filenames)\n",
    "    \n",
    "    file_name = os.path.join(cwd, 'model', 'feature_{0}_{1}.h5'.format(MODEL.__name__, 171023))\n",
    "    print(file_name)\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "    with h5py.File(file_name) as h:\n",
    "        h.create_dataset(\"train\", data=train)\n",
    "        h.create_dataset(\"train_label\", data=train_generator.classes)\n",
    "        h.create_dataset(\"val\", data=val)\n",
    "        h.create_dataset(\"val_label\", data=val_generator.classes)\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "        \n",
    "    print(train.shape)\n",
    "    print(len(train_generator.classes))\n",
    "    print(val.shape)\n",
    "    print(len(val_generator.classes))\n",
    "    print(test.shape)\n",
    "    \n",
    "    print(dir(train_generator))\n",
    "    print(train_generator.num_class)\n",
    "    print(train_generator.samples)\n",
    "    print(train_generator.image_shape)\n",
    "    print(train_generator.classes)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print('Spend time: {0} s'.format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No model found in config file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-246b45a8e269>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mkeras_model_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'keras_model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mweigths_file_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_model_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweigths_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_config'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No model found in config file.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No model found in config file."
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "keras_model_path = os.path.join(cwd, 'keras_model')\n",
    "weigths_file_path = os.path.join(keras_model_path, 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "model = load_model(weigths_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16 start.\n",
      "Found 53879 images belonging to 80 classes.\n",
      "Found 7120 images belonging to 80 classes.\n",
      "Found 7040 images belonging to 1 classes.\n",
      "7040/7040 [==============================] - 169s   \n",
      "E:\\SceneClassification\\model\\feature_VGG16_171023.h5\n",
      "(53879, 512)\n",
      "53879\n",
      "(7120, 512)\n",
      "7120\n",
      "(7040, 512)\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__next__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_flow_index', 'batch_index', 'batch_size', 'class_indices', 'class_mode', 'classes', 'color_mode', 'data_format', 'directory', 'filenames', 'image_data_generator', 'image_shape', 'index_generator', 'lock', 'n', 'next', 'num_class', 'reset', 'samples', 'save_format', 'save_prefix', 'save_to_dir', 'shuffle', 'target_size', 'total_batches_seen']\n",
      "80\n",
      "53879\n",
      "(224, 224, 3)\n",
      "[ 0  0  0 ..., 79 79 79]\n",
      "Spend time: 2098.7899589538574 s\n"
     ]
    }
   ],
   "source": [
    "get_features(VGG16, (224, 224), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG19 start.\n",
      "Found 53879 images belonging to 80 classes.\n",
      "Found 7120 images belonging to 80 classes.\n",
      "Found 7040 images belonging to 1 classes.\n",
      "7120/7120 [==============================] - 119s   \n",
      "7037/7040 [============================>.] - ETA: 0sE:\\SceneClassification\\model\\feature_VGG19_171023.h5\n",
      "(53879, 512)\n",
      "53879\n",
      "(7120, 512)\n",
      "7120\n",
      "(7040, 512)\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__next__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_flow_index', 'batch_index', 'batch_size', 'class_indices', 'class_mode', 'classes', 'color_mode', 'data_format', 'directory', 'filenames', 'image_data_generator', 'image_shape', 'index_generator', 'lock', 'n', 'next', 'num_class', 'reset', 'samples', 'save_format', 'save_prefix', 'save_to_dir', 'shuffle', 'target_size', 'total_batches_seen']\n",
      "80\n",
      "53879\n",
      "(224, 224, 3)\n",
      "[ 0  0  0 ..., 79 79 79]\n",
      "Spend time: 1151.726350069046 s\n"
     ]
    }
   ],
   "source": [
    "get_features(VGG19, (224, 224), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50 start.\n",
      "Found 53879 images belonging to 80 classes.\n",
      "Found 7120 images belonging to 80 classes.\n",
      "Found 7040 images belonging to 1 classes.\n",
      "7040/7040 [==============================] - 186s   \n",
      "E:\\SceneClassification\\model\\feature_ResNet50_171023.h5\n",
      "(53879, 2048)\n",
      "53879\n",
      "(7120, 2048)\n",
      "7120\n",
      "(7040, 2048)\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__next__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_flow_index', 'batch_index', 'batch_size', 'class_indices', 'class_mode', 'classes', 'color_mode', 'data_format', 'directory', 'filenames', 'image_data_generator', 'image_shape', 'index_generator', 'lock', 'n', 'next', 'num_class', 'reset', 'samples', 'save_format', 'save_prefix', 'save_to_dir', 'shuffle', 'target_size', 'total_batches_seen']\n",
      "80\n",
      "53879\n",
      "(224, 224, 3)\n",
      "[ 0  0  0 ..., 79 79 79]\n",
      "Spend time: 2118.8636145591736 s\n"
     ]
    }
   ],
   "source": [
    "get_features(ResNet50, (224, 224), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xception start.\n",
      "preprocess_input\n",
      "Found 53879 images belonging to 80 classes.\n",
      "Found 7120 images belonging to 80 classes.\n",
      "Found 7040 images belonging to 1 classes.\n",
      "7040/7040 [==============================] - 269s   \n",
      "E:\\SceneClassification\\model\\feature_Xception_171023.h5\n",
      "(53879, 2048)\n",
      "53879\n",
      "(7120, 2048)\n",
      "7120\n",
      "(7040, 2048)\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__next__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_flow_index', 'batch_index', 'batch_size', 'class_indices', 'class_mode', 'classes', 'color_mode', 'data_format', 'directory', 'filenames', 'image_data_generator', 'image_shape', 'index_generator', 'lock', 'n', 'next', 'num_class', 'reset', 'samples', 'save_format', 'save_prefix', 'save_to_dir', 'shuffle', 'target_size', 'total_batches_seen']\n",
      "80\n",
      "53879\n",
      "(299, 299, 3)\n",
      "[ 0  0  0 ..., 79 79 79]\n",
      "Spend time: 2418.4485199451447 s\n"
     ]
    }
   ],
   "source": [
    "get_features(Xception, (299, 299), 1, xception.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV3 start.\n",
      "preprocess_input\n",
      "Found 53879 images belonging to 80 classes.\n",
      "Found 7120 images belonging to 80 classes.\n",
      "Found 7040 images belonging to 1 classes.\n",
      "53879/53879 [==============================] - 3358s  \n",
      "4015/7120 [===============>..............] - ETA: 193s"
     ]
    }
   ],
   "source": [
    "get_features(InceptionV3, (299, 299), 1, inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
